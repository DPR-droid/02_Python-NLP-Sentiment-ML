{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment textblob versus Vader\n",
    "\n",
    "https://www.youtube.com/watch?v=qTyj2R-wcks&t=921s\n",
    "\n",
    "### textblob Resource punkt not found.\n",
    "Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "open python cli\n",
    "\n",
    "    import nltk\n",
    "    nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TextBlob Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the output of sentiment using textblob\n",
    "# Imports\n",
    "\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The string to be analyzed \n",
    "analysis = TextBlob(\"This is a really cool feature of textBlob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cmpkey', '_compare', '_create_sentence_objects', '_strkey', 'analyzer', 'classifier', 'classify', 'correct', 'detect_language', 'ends_with', 'endswith', 'find', 'format', 'index', 'join', 'json', 'lower', 'ngrams', 'noun_phrases', 'np_counts', 'np_extractor', 'parse', 'parser', 'polarity', 'pos_tagger', 'pos_tags', 'raw', 'raw_sentences', 'replace', 'rfind', 'rindex', 'sentences', 'sentiment', 'sentiment_assessments', 'serialized', 'split', 'starts_with', 'startswith', 'string', 'strip', 'stripped', 'subjectivity', 'tags', 'title', 'to_json', 'tokenize', 'tokenizer', 'tokens', 'translate', 'translator', 'upper', 'word_counts', 'words']\n"
     ]
    }
   ],
   "source": [
    "# List all different features by using the dir\n",
    "print(dir(analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est une fonctionnalité vraiment cool de TextBlob\n",
      "Dies ist eine wirklich coole Funktion von TextBlob\n",
      "Esta es una característica realmente genial de TextBlob\n"
     ]
    }
   ],
   "source": [
    "# This feature is using the translate option to french, spanish, german\n",
    "# https://github.com/sloria/TextBlob\n",
    "print(analysis.translate(from_lang='en', to='fr'))\n",
    "print(analysis.translate(from_lang='en', to='de'))\n",
    "print(analysis.translate(from_lang='en', to='es'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('really', 'RB'), ('cool', 'JJ'), ('feature', 'NN'), ('of', 'IN'), ('textBlob', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# List the tag associated \n",
    "# https://textblob.readthedocs.io/en/latest/quickstart.html#part-of-speech-tagging\n",
    "# Understand each of the tags go to \n",
    "# https://www.geeksforgeeks.org/python-part-of-speech-tagging-using-textblob/\n",
    "# NN noun, singular ‘desk’\n",
    "# DT determiner\n",
    "# VBZ verb, 3rd person sing. present takes\n",
    "\n",
    "\n",
    "print(analysis.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.35, subjectivity=0.65)\n"
     ]
    }
   ],
   "source": [
    "# https://textblob.readthedocs.io/en/latest/quickstart.html#sentiment-analysis\n",
    "# The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). \n",
    "# The polarity score is a float within the range [-1.0, 1.0]. \n",
    "# The subjectivity is a float within the range [0.0, 1.0] \n",
    "# where 0.0 is very objective and  \n",
    "# 1.0 is very subjective.\n",
    "\n",
    "# output \n",
    "# \"This is a really cool feature of textBlob\"\n",
    "# Sentiment(polarity=0.35, subjectivity=0.65)\n",
    "# This sentence is positive at 0.35 and subjective at 0.65  \n",
    "\n",
    "print(analysis.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 71.11777944486121% via 5332 samples\n",
      "Negative accuracy = 55.8702175543886% via 5332 samples\n"
     ]
    }
   ],
   "source": [
    "# Set counts for positive\n",
    "# String count positive\n",
    "pos_count = 0\n",
    "# Set count with positive sentiment\n",
    "pos_correct = 0\n",
    "\n",
    "# Read the text file positive.txt\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the polarity to greater than 0\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            # pos_correct add 1 if positive sentiment detected\n",
    "            pos_correct += 1\n",
    "        # pos_count add 1 to string count \n",
    "        pos_count +=1\n",
    "\n",
    "\n",
    "# Set counts for negative\n",
    "# String count negative\n",
    "neg_count = 0\n",
    "# Set count with negative sentiment\n",
    "neg_correct = 0\n",
    "\n",
    "# Read the text file negative.txt\n",
    "with open(\"negative.txt\",\"r\", encoding='latin-1') as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the polarity to less than or equal to 0\n",
    "        if analysis.sentiment.polarity <= 0:\n",
    "            # neg_correct add 1 if negative sentiment detected\n",
    "            neg_correct += 1\n",
    "        # neg_count add 1 to string count\n",
    "        neg_count +=1\n",
    "\n",
    "# Print Positive accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "\n",
    "# Print Negative accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 29.116465863453815% via 996 samples\n",
      "Negative accuracy = 76.03369065849922% via 1306 samples\n"
     ]
    }
   ],
   "source": [
    "# Add low degree of subjectivity \n",
    "\n",
    "# Set counts for positive\n",
    "# String count positive\n",
    "pos_count = 0\n",
    "# Set count with positive sentiment\n",
    "pos_correct = 0\n",
    "\n",
    "# Read the text file positive.txt\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the subjectivity to less than 0.3\n",
    "        if analysis.sentiment.subjectivity < 0.3:\n",
    "            # Set the polarity to greater than 0\n",
    "            if analysis.sentiment.polarity > 0:\n",
    "                # pos_correct add 1 if positive sentiment detected\n",
    "                pos_correct += 1\n",
    "            # pos_count add 1 to string count \n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "# Set counts for negative\n",
    "# String count negative\n",
    "neg_count = 0\n",
    "# Set count with negative sentiment\n",
    "neg_correct = 0\n",
    "\n",
    "# Read the text file negative.txt\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the subjectivity to less than 0.3\n",
    "        if analysis.sentiment.subjectivity < 0.3:\n",
    "            # Set the polarity to less than or equal to 0\n",
    "            if analysis.sentiment.polarity <= 0:\n",
    "                # neg_correct add 1 if negative sentiment detected\n",
    "                neg_correct += 1\n",
    "            # neg_count add 1 to string count\n",
    "            neg_count +=1\n",
    "\n",
    "# Print Positive accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "\n",
    "# Print Negative accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 76.08695652173914% via 414 samples\n",
      "Negative accuracy = 68.6046511627907% via 344 samples\n"
     ]
    }
   ],
   "source": [
    "# Add high degree of subjectivity \n",
    "\n",
    "# Set counts for positive\n",
    "# String count positive\n",
    "pos_count = 0\n",
    "# Set count with positive sentiment\n",
    "pos_correct = 0\n",
    "\n",
    "# Read the text file positive.txt\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the subjectivity to less than 0.3\n",
    "        if analysis.sentiment.subjectivity > 0.9:\n",
    "            # Set the polarity to greater than 0\n",
    "            if analysis.sentiment.polarity > 0:\n",
    "                # pos_correct add 1 if positive sentiment detected\n",
    "                pos_correct += 1\n",
    "            # pos_count add 1 to string count \n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "# Set counts for negative\n",
    "# String count negative\n",
    "neg_count = 0\n",
    "# Set count with negative sentiment\n",
    "neg_correct = 0\n",
    "\n",
    "# Read the text file negative.txt\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the subjectivity to less than 0.3\n",
    "        if analysis.sentiment.subjectivity > 0.9:\n",
    "            # Set the polarity to less than or equal to 0\n",
    "            if analysis.sentiment.polarity <= 0:\n",
    "                # neg_correct add 1 if negative sentiment detected\n",
    "                neg_correct += 1\n",
    "            # neg_count add 1 to string count\n",
    "            neg_count +=1\n",
    "\n",
    "# Print Positive accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "\n",
    "# Print Negative accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 100.0% via 3790 samples\n",
      "Negative accuracy = 100.0% via 2072 samples\n"
     ]
    }
   ],
   "source": [
    "# Add high degree of subjectivity \n",
    "\n",
    "# Set counts for positive\n",
    "# String count positive\n",
    "pos_count = 0\n",
    "# Set count with positive sentiment\n",
    "pos_correct = 0\n",
    "\n",
    "# Read the text file positive.txt\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the subjectivity to less than 0.3\n",
    "        if analysis.sentiment.polarity >= 0.0001:\n",
    "            # Set the polarity to greater than 0\n",
    "            if analysis.sentiment.polarity > 0:\n",
    "                # pos_correct add 1 if positive sentiment detected\n",
    "                pos_correct += 1\n",
    "            # pos_count add 1 to string count \n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "# Set counts for negative\n",
    "# String count negative\n",
    "neg_count = 0\n",
    "# Set count with negative sentiment\n",
    "neg_correct = 0\n",
    "\n",
    "# Read the text file negative.txt\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # TextBlob to read string\n",
    "        analysis = TextBlob(line)\n",
    "        # Set the subjectivity to less than 0.3\n",
    "        if analysis.sentiment.polarity <= -0.0001:\n",
    "            # Set the polarity to less than or equal to 0\n",
    "            if analysis.sentiment.polarity <= 0:\n",
    "                # neg_correct add 1 if negative sentiment detected\n",
    "                neg_correct += 1\n",
    "            # neg_count add 1 to string count\n",
    "            neg_count +=1\n",
    "\n",
    "# Print Positive accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "\n",
    "# Print Negative accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Vader Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vader\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "# The compound score is computed by summing the valence scores of each word in the lexicon, \n",
    "# adjusted according to the rules, and then normalized to be between -1 (most extreme negative) \n",
    "# and +1 (most extreme positive). This is the most useful metric if you want a \n",
    "# single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, \n",
    "# weighted composite score' is accurate.\n",
    "\n",
    "# The pos, neu, and neg scores are ratios for proportions of text that fall in each category \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.755, 'pos': 0.245, 'compound': 0.3804}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Sentiment \n",
    "\n",
    "analysis = analyzer.polarity_scores(\"This is a really cool feature of Vader Sentiment\")\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 70.18004501125282% via 5332 samples\n",
      "Negative accuracy = 57.389347336834206% via 5332 samples\n"
     ]
    }
   ],
   "source": [
    "# Set counts for positive\n",
    "# String count positive\n",
    "pos_count = 0\n",
    "# Set count with positive sentiment\n",
    "pos_correct = 0\n",
    "\n",
    "# Read the text file positive.txt\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # Vader to read string\n",
    "        analysis = analyzer.polarity_scores(line)\n",
    "        # Select the compound score from Vader to greater than 0\n",
    "        if analysis['compound'] > 0:\n",
    "            # pos_correct add 1 if positive sentiment detected\n",
    "            pos_correct += 1\n",
    "        # pos_count add 1 to string count \n",
    "        pos_count +=1\n",
    "\n",
    "\n",
    "# Set counts for negative\n",
    "# String count negative\n",
    "neg_count = 0\n",
    "# Set count with negative sentiment\n",
    "neg_correct = 0\n",
    "\n",
    "# Read the text file negative.txt\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # Vader to read string\n",
    "        analysis = analyzer.polarity_scores(line)\n",
    "        # Select the compound score from Vader\n",
    "        if analysis['compound'] <= 0:\n",
    "            # neg_correct add 1 if negative sentiment detected\n",
    "            neg_correct += 1\n",
    "        # neg_count add 1 to string count\n",
    "        neg_count +=1\n",
    "\n",
    "# Print Positive accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "\n",
    "# Print Negative accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cjhutto/vaderSentiment#about-the-scoring\n",
    "\n",
    "# It is also useful for researchers who would like to set standardized thresholds for \n",
    "# classifying sentences as either positive, neutral, or negative. \n",
    "# Typical threshold values (used in the literature cited on this page) are:\n",
    "\n",
    "# positive sentiment: compound score >= 0.05\n",
    "# neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "# negative sentiment: compound score <= -0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 87.66037735849056% via 2650 samples\n",
      "Negative accuracy = 49.56140350877193% via 1824 samples\n"
     ]
    }
   ],
   "source": [
    "# Adding a threshold to remove data strings that does not meet the criteria\n",
    "# Set counts for positive\n",
    "# String count positive\n",
    "pos_count = 0\n",
    "# Set count with positive sentiment\n",
    "pos_correct = 0\n",
    "\n",
    "# Add a Threshold variable\n",
    "threshold = 0.5\n",
    "\n",
    "# Read the text file positive.txt\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # Vader to read string\n",
    "        analysis = analyzer.polarity_scores(line)\n",
    "        # Test string against the theshold\n",
    "        if analysis['compound'] >= threshold or analysis['compound'] <= -threshold:\n",
    "        # Select the compound score from Vader to greater than 0\n",
    "            if analysis['compound'] > 0:\n",
    "                # pos_correct add 1 if positive sentiment detected\n",
    "                pos_correct += 1\n",
    "            # pos_count add 1 to string count \n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "# Set counts for negative\n",
    "# String count negative\n",
    "neg_count = 0\n",
    "# Set count with negative sentiment\n",
    "neg_correct = 0\n",
    "\n",
    "# Read the text file negative.txt\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # Vader to read string\n",
    "        analysis = analyzer.polarity_scores(line)\n",
    "        # Test string against the theshold\n",
    "        if analysis['compound'] >= threshold or analysis['compound'] <= -threshold:\n",
    "        # Test string against the theshold less than or equal to 0 \n",
    "            if analysis['compound'] <= 0:\n",
    "                # neg_correct add 1 if negative sentiment detected\n",
    "                neg_correct += 1\n",
    "            # neg_count add 1 to string count\n",
    "            neg_count +=1\n",
    "\n",
    "# Print Positive accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "\n",
    "# Print Negative accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 81.0302734375% via 4096 samples\n",
      "Negative accuracy = 89.26862611073138% via 2926 samples\n"
     ]
    }
   ],
   "source": [
    "# Looking at the look only for signals where the opposite is lower, or non-existent\n",
    "# Set counts for positive\n",
    "# String count positive\n",
    "pos_count = 0\n",
    "# Set count with positive sentiment\n",
    "pos_correct = 0\n",
    "\n",
    "# Read the text file positive.txt\n",
    "with open(\"positive.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # Vader to read string\n",
    "        analysis = analyzer.polarity_scores(line)\n",
    "        # If value neg is not greater-than 0.1\n",
    "        if not analysis['neg'] > 0.1:\n",
    "            # If value pos value minus the neg value is greater-than to greater than 0\n",
    "            if analysis['pos']-analysis['neg'] > 0:\n",
    "                # pos_correct add 1 if positive sentiment detected\n",
    "                pos_correct += 1\n",
    "            # pos_count add 1 to string count \n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "# Set counts for negative\n",
    "# String count negative\n",
    "neg_count = 0\n",
    "# Set count with negative sentiment\n",
    "neg_correct = 0\n",
    "\n",
    "# Read the text file negative.txt\n",
    "with open(\"negative.txt\",\"r\") as f:\n",
    "    # Read lines split by return\n",
    "    for line in f.read().split('\\n'):\n",
    "        # Vader to read string\n",
    "        analysis = analyzer.polarity_scores(line)\n",
    "        # If value pos is not greater-than 0.1\n",
    "        if not analysis['pos'] > 0.1:\n",
    "        # If value pos value minus the neg value less than or equal to 0 \n",
    "            if analysis['pos']-analysis['neg'] <= 0:\n",
    "                # neg_correct add 1 if negative sentiment detected\n",
    "                neg_correct += 1\n",
    "            # neg_count add 1 to string count\n",
    "            neg_count +=1\n",
    "\n",
    "# Print Positive accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "\n",
    "# Print Negative accuracy by dividing total of amount detected versus total strings in file\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
